{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6cbbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy.core as op\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def read_DMX_file(DMXfile, fix=True, defaultnet=''):\n",
    "    # DMX read support now (2023) included in ObsPy. Was not available for the Montserrat ASN conversion in 2019.\n",
    "    # This produces same result as converting DMX to SAC with sud2sac.exe in Win-SUDS, and then reading into ObsPy\n",
    "    # Has also been tested against sud2gse.exe.\n",
    "    # sud2msed.exe is messier, because that program completely loses all tr.id info when converting, so all tr.id set to ...\n",
    "    # Tested on data from Montserrat 1995-6 and Pinatubo 1991\n",
    "    #\n",
    "    # ObsPy DMX reader inserts \"unk\" in place of an unknown network. We do not want this.\n",
    "    #\n",
    "    # ObsPy DMX reader reads DMXfile as uint16 and so is all +ve. \n",
    "    # sud2sac.exe converts to numbers either side of 0. \n",
    "    # Subtracting 2048 from each sample of tr.data corrects data read in using ObsPy DMX reader to match that from SAC\n",
    "    #\n",
    "    # Obspy Miniseed writer needs float, not int, so recast as float.\n",
    "    #\n",
    "    # Passing fix=False will just run ObsPy DMX reader without applying any corrections.\n",
    "\n",
    "    print('Reading %s' % DMXfile)\n",
    "    try:\n",
    "        st = op.read(DMXfile)\n",
    "        print('- read okay')\n",
    "        if fix:\n",
    "            for tr in st:\n",
    "                # ObsPy DMX reader sets network to \"unk\" if blank. We'd rather keep it blank, or \n",
    "                # set with explicitly passing defaultnet named argument.\n",
    "                if tr.stats.network == 'unk':\n",
    "                    tr.stats.network = defaultnet\n",
    "                    \n",
    "                # ObsPy DMX reader falses adds 2048 to each data sample. Remove that here.\n",
    "                # Also change data type of tr.data from uint to float so we can write trace to MiniSEED later   \n",
    "                tr.data = tr.data.astype(float) - 2048.0 \n",
    "    except:\n",
    "        print('- ObsPy cannot read this demultiplexed SUDS file')        \n",
    "    return st\n",
    "\n",
    "def _run_command(cmd, show_terminal_output=True, errorStr=''):\n",
    "    success = True\n",
    "    print(cmd)\n",
    "    result = subprocess.run(cmd, stdout=subprocess.PIPE) #, check=True)  \n",
    "    #print(result)\n",
    "    if show_terminal_output:\n",
    "        if result.stdout:\n",
    "            #print('\\n')\n",
    "            print(\"STDOUT:\", result.stdout.decode())  # decode the byte-string\n",
    "            #print('\\n')\n",
    "        if result.stderr:\n",
    "            print(\"STDERR:\", result.stderr.decode())\n",
    "            #print('\\n')\n",
    "    if result.stderr:\n",
    "        return 1, result\n",
    "    elif errorStr and result.stdout.decode().find(errorStr):\n",
    "        return 2, result\n",
    "    else:\n",
    "        return 0, result\n",
    "   \n",
    "\n",
    "def run_IRIG(irigexe, DMXfile, IRIGfile):\n",
    "    \n",
    "    if not os.path.exists(DMXfile):\n",
    "        print(\"Cannot find %s\" % DMXfile)\n",
    "        return\n",
    "    \n",
    "    if IRIGfile!=DMXfile:\n",
    "        shutil.copyfile(DMXfile, IRIGfile)   \n",
    "    \n",
    "    # Use irig.exe to time correct SUDS DMX file\n",
    "    print('Time correcting ' + IRIGfile)\n",
    "    cmd = \"%s %s\" % (irigexe, IRIGfile)\n",
    "\n",
    "    rtncode, result = _run_command(cmd, errorStr='ERROR')\n",
    "    \n",
    "    irig_delta_correction_secs = None\n",
    "    try:\n",
    "        index = result.stdout.decode().find('Delta T:')\n",
    "        irig_delta_correction_secs = float(result.stdout.decode()[index+16:index+27])\n",
    "    except:\n",
    "        print('Could not parse IRIG Delta T. Might have a Station not found: IRIG')\n",
    "    if rtncode:\n",
    "        print('IRIG failed')\n",
    "    return rtncode, irig_delta_correction_secs\n",
    "\n",
    "\n",
    "def SUDSDMX_to_MSED_to_STREAM(sud2msedexe, DMXfile): \n",
    "    # SUDS DMX to MSEED using sud2msed. Then ObsPy to read MSEED into Stream\n",
    "    \n",
    "    # Create empty Stream object to return\n",
    "    st = op.Stream() \n",
    "    \n",
    "    if not os.path.exists(DMXfile):\n",
    "        print(\"Cannot find %s\" % DMXfile)\n",
    "        return st\n",
    "    \n",
    "    # Step 1: Use sud2msed.exe to convert SUDS DMX file to MSEED file\n",
    "    print('Converting ' + DMXfile + ' to MSEED file')\n",
    "    MSEEDfile = DMXfile.replace('.DMX','.MSEED')\n",
    "    cmd = \"%s %s %s\" % (sud2msedexe, DMXfile, MSEEDfile)\n",
    "    rtncode, result = _run_command(cmd)\n",
    "    if rtncode:\n",
    "        print('Conversion to MSEED failed')\n",
    "        return st    \n",
    "    \n",
    "    # Step 2: Read the MSEED file \n",
    "    if not os.path.exists(MSEEDfile):\n",
    "        print(\"Cannot find %s\" % MSEEDfile)\n",
    "        return st   \n",
    "\n",
    "    try:\n",
    "        print('- Reading ' + MSEEDfile)        \n",
    "        st = op.read(MSEEDfile)   \n",
    "    except:\n",
    "        print('  - FAILED')   \n",
    "    return st\n",
    "\n",
    "def SUDSDMX_to_SAC_to_STREAM(sud2sacexe, DMXfile): \n",
    "    # SUDS DMX to SAC using sud2sac. Then ObsPy to read SAC into Stream\n",
    "    # Sacfiles are removed after processing to prevent filling up filesystem.\n",
    "    \n",
    "    # Create empty Stream object to return\n",
    "    st = op.Stream() \n",
    "    \n",
    "    if not os.path.exists(DMXfile):\n",
    "        print(\"Cannot find %s\" % DMXfile)\n",
    "        return st\n",
    "    \n",
    "    # Step 1: Use sud2sac.exe to convert SUDS DMX file to SAC files\n",
    "    print('Converting ' + DMXfile + ' to SAC files')\n",
    "    cmd = \"%s %s\" % (sud2sacexe, DMXfile)\n",
    "    rtncode, result = _run_command(cmd)\n",
    "    #print(rtncode)\n",
    "    if rtncode:\n",
    "        print('Conversion to SAC failed')\n",
    "        return st\n",
    "    \n",
    "    # Step 2: Merge the SAC files into a single valid Miniseed file \n",
    "    DMXbasename = os.path.basename(DMXfile).replace('.DMX','')\n",
    "    print('Reading from SAC files')\n",
    "    \n",
    "    sacfilelist = glob.glob(DMXbasename + '.sac-???')\n",
    "    print(sacfilelist)\n",
    "    if len(sacfilelist) > 0:\n",
    "        for sacfile in sacfilelist:\n",
    "            print('- Reading ' + sacfile)\n",
    "            try:\n",
    "                sacst = op.read(sacfile);\n",
    "                #tr.plot();\n",
    "            except:\n",
    "                print('  - FAILED')\n",
    "            else:\n",
    "                for tr in sacst:\n",
    "                    tr2 = tr.copy() #.detrend()\n",
    "                    if not (all(tr2.data==0)): # remove blank channels\n",
    "                        st = st + tr\n",
    "    else:\n",
    "        print('FAILED. No SAC files found')\n",
    "    return st\n",
    "\n",
    "def SUDSDMX_to_GSE_to_STREAM(sud2gseexe, DMXfile): \n",
    "    # SUDS DMX to GSE using sud2gse. Then ObsPy to read GSE into Stream\n",
    "    import subprocess\n",
    "    \n",
    "    # Create empty Stream object to return\n",
    "    st = op.Stream() \n",
    "    \n",
    "    if not os.path.exists(DMXfile):\n",
    "        print(\"Cannot find %s\" % DMXfile)\n",
    "        return st\n",
    "    \n",
    "    # Step 1: Use sud2gse.exe to convert SUDS DMX file to GSEfile\n",
    "    print('Converting ' + DMXfile + ' to GSE file')\n",
    "    cmd = \"%s %s\" % (sud2gseexe, DMXfile)\n",
    "    rtncode, result = _run_command(cmd)\n",
    "    if rtncode:\n",
    "        print('Conversion to GSE failed')\n",
    "        return st\n",
    "    \n",
    "    # Step 2: Read the GSE file \n",
    "    GSEfile = DMXfile.replace('.DMX','.GSE')\n",
    "    if not os.path.exists(GSEfile):\n",
    "        print(\"Cannot find %s\" % GSEfile)\n",
    "        return st   \n",
    "\n",
    "    try:\n",
    "        print('- Reading ' + GSEfile)        \n",
    "        st = op.read(GSEfile)   \n",
    "    except:\n",
    "        print('  - FAILED')   \n",
    "    return st\n",
    "''' \n",
    "def checkIfConstant(x):\n",
    "    bool_equal = np.all(x == x[0])\n",
    "    value = None\n",
    "    if bool_equal:\n",
    "        value=x[0]\n",
    "    return bool_equal, value\n",
    "'''\n",
    "\n",
    "def _compare_Trace_timing(tr0, tr1, errormsglist=[], okay=True):\n",
    "    if not tr0.stats.npts == tr1.stats.npts:\n",
    "        errormsglist.append(\"ERROR: different number of samples: %d %d\" % (tr0.stats.npts, tr1.stats.npts) )\n",
    "        okay = False\n",
    "    if not tr0.stats.sampling_rate == tr1.stats.sampling_rate:\n",
    "        errormsglist.append(\"ERROR: different sampling rates: %.2f Hz %.2f Hz\" % \n",
    "        (tr0.stats.sampling_rate, tr1.stats.sampling_rate)  ) \n",
    "        okay = False\n",
    "    if not (all(tr0.times()==tr1.times())):\n",
    "        errormsglist.append(\"ERROR: different time array\")  \n",
    "        okay = False\n",
    "        if not (tr0.stats.starttime==tr1.stats.starttime):\n",
    "            errormsglist.append('ERROR: start times differ by %.3f s' % (tr0.stats.starttime - tr1.stats.starttime) )\n",
    "        if not (tr0.stats.endtime==tr1.stats.endtime):\n",
    "            errormsglist.append('ERROR: end times differ by %.3f s' % (tr0.stats.endtime - tr1.stats.endtime) )            \n",
    "        if not (tr0.times()[-1]==tr1.times()[-1]):\n",
    "            errormsglist.append('ERROR: different durations %.3f s %.3f s' % (tr0.times()[-1], tr1.times()[-1]) )                    \n",
    "    #return errormsglist, okay  \n",
    "    return okay\n",
    "\n",
    "def _compare_Trace_data(tr0, tr1, errormsglist=[], okay=True):\n",
    "    if not (all(tr0.data==tr1.data)):\n",
    "        same=(tr0.data==tr1.data)\n",
    "        #diff1=tr1.data - tr0.data\n",
    "        #errormsglist.append('- out of %d samples, %d same' % (tr0.stats.npts, same.sum()) )\n",
    "        #print('Differences: max: %f, mean: %f' % (np.max(diff1), np.mean(diff1)) )\n",
    "        if (all(tr0.copy().detrend('linear').data == tr1.copy().detrend('linear').data)):\n",
    "            errormsglist.append('ERROR: different data array. After detrending, traces are identical')\n",
    "        else:\n",
    "            errormsglist.append('ERROR: different data array. After detrending, traces still different')\n",
    "        okay = False    \n",
    "    #return errormsglist, okay\n",
    "    return okay\n",
    "\n",
    "def _compare_Trace_info(tr0, tr1):\n",
    "    duration_fraction = np.abs(tr0.times()[-1]-tr1.times()[-1])/tr0.times()[-1]\n",
    "    thisList = [('id',tr0.id, tr1.id, tr0.id==tr1.id),\n",
    "              ('npts', tr0.stats.npts, tr1.stats.npts, tr0.stats.npts == tr1.stats.npts),\n",
    "              ('sampling_rate', tr0.stats.sampling_rate, tr1.stats.sampling_rate, \n",
    "               np.abs(tr0.stats.sampling_rate - tr1.stats.sampling_rate)<0.01),\n",
    "              ('startdate', tr0.stats.starttime.strftime('%Y/%m/%d'), tr1.stats.starttime.strftime('%Y/%m/%d'), \n",
    "               tr0.stats.starttime.strftime('%Y/%m/%d') == tr1.stats.starttime.strftime('%Y/%m/%d')),\n",
    "              ('starttime', tr0.stats.starttime.strftime('%H:%M:%S.%f'), tr1.stats.starttime.strftime('%H:%M:%S.%f'), tr0.stats.starttime == tr1.stats.starttime),\n",
    "              ('endtime', tr0.stats.endtime.strftime('%H:%M:%S.%f'), tr1.stats.endtime.strftime('%H:%M:%S.%f'), tr0.stats.endtime == tr1.stats.endtime),\n",
    "              ('duration', tr0.times()[-1], tr1.times()[-1], duration_fraction < 0.001),\n",
    "              ('data_mean', np.nanmean(tr0.data), np.nanmean(tr1.data), np.nanmean(tr0.data) == np.nanmean(tr1.data) ),\n",
    "              ('data_std', np.std(tr0.data), np.std(tr1.data), np.std(tr0.data) == np.std(tr1.data) )]\n",
    "    thisDf = pd.DataFrame(thisList, columns=['metric', 'tr0', 'tr1', 'equal'])\n",
    "    thisDf.set_index('metric')\n",
    "    return thisDf\n",
    "\n",
    "def _summarise_Trace_info(thisDf):\n",
    "    if thisDf['equal'].all():\n",
    "        #print('Traces are the same')\n",
    "        return 0\n",
    "    else:\n",
    "        print('Traces are different')\n",
    "        display(HTML(thisDf.to_html()))\n",
    "        return 1\n",
    "    \n",
    "\n",
    "def _print_errormsglist(errormsglist):\n",
    "    errormsgset = set(sorted(errormsglist))\n",
    "    #print(errormsglist)\n",
    "    for errormsg in list(errormsgset):\n",
    "        print(errormsg)    \n",
    "\n",
    "def compare_Streams(st0_in, st1_in):\n",
    "    # remove any IRIG trace so it does not mess up comparisons\n",
    "    st0 = st0_in.copy()\n",
    "    st1 = st1_in.copy()\n",
    "    remove_IRIG_channel(st0)\n",
    "    remove_IRIG_channel(st1)\n",
    "    if not(len(st0)==len(st1)):\n",
    "        print('ERROR: different number of Trace objects: %d %d' % (len(st0), len(st1)))\n",
    "    ids0 = [tr.id for tr in st0]\n",
    "    ids1 = [tr.id for tr in st1]\n",
    "    \n",
    "    errormsglist=[]  \n",
    "    \n",
    "    ids_match = True\n",
    "    if not (ids0==ids1):\n",
    "        print('ERROR: trace ID lists are different')\n",
    "        ids_match = False\n",
    "        print(ids0)\n",
    "        print(ids1) \n",
    "        stations0 = sorted([tr.stats.station for tr in st0])\n",
    "        stations1 = sorted([tr.stats.station for tr in st1])\n",
    "        if not (stations0==stations1):\n",
    "            print('ERROR: station lists are different too. Cannot compare trace by trace.\\nWill just compare timing info of first trace of each.')\n",
    "            #errormsglist, okay = _compare_Trace_timing(st0[0], st1[0])  \n",
    "            #_print_errormsglist(errormsglist)\n",
    "            thisDf = _compare_Trace_info(st0[0], st1[0])       \n",
    "            _summarise_Trace_info(thisDf)\n",
    "            return\n",
    "        else:\n",
    "            print('station lists are same')\n",
    "    else:\n",
    "        print('trace ID lists are same')\n",
    "        \n",
    "    rtncodeSum = 0    \n",
    "    for i,tr0 in enumerate(st0):\n",
    "        okay = True\n",
    "        this_sta = tr0.stats.station\n",
    "        if ids_match:\n",
    "            tr1 = st1.select(id=tr0.id)[0]\n",
    "        else:\n",
    "            tr1 = st1.select(station=this_sta)[0]\n",
    "        '''\n",
    "        okay = _compare_Trace_timing(tr0, tr1, errormsglist=errormsglist, okay=okay)         \n",
    "        okay = _compare_Trace_timing(tr0, tr1, errormsglist=errormsglist, okay=okay) \n",
    "        if okay:\n",
    "            errormsglist.append('Trace #%d, %s -> %s, is OK' % (i, tr0.id, tr1.id))\n",
    "        else:\n",
    "            errormsglist.append('Trace #%d, %s -> %s, FAILED' % (i, tr0.id, tr1.id))\n",
    "        '''\n",
    "        thisDf = _compare_Trace_info(tr0, tr1)\n",
    "        rtncode = _summarise_Trace_info(thisDf)\n",
    "        rtncodeSum += rtncode\n",
    "    if rtncodeSum==0:\n",
    "        print('!!! Stream objects are same !!!')\n",
    "    #_print_errormsglist(errormsglist)\n",
    "\n",
    "        \n",
    "def fix_NSLC_Pinatubo(st, FDSNnet):\n",
    "    for tr in st:\n",
    "        sta = tr.stats.station\n",
    "        tr.stats.network = FDSNnet\n",
    "        tr.stats.station = sta[:-1]\n",
    "        tr.stats.channel = 'EH%c' % sta[-1]\n",
    "        print('Converting %s => %s' % (sta, tr.id))\n",
    "        \n",
    "def fix_sampling_rate(st, fs=100.0):\n",
    "    for tr in st:\n",
    "        tr.stats.sampling_rate=fs          \n",
    "\n",
    "def remove_IRIG_channel(st):\n",
    "    for tr in st:\n",
    "        if tr.stats.station=='IRIG':\n",
    "            st.remove(tr) # we do not want to keep the IRIG trace\n",
    "\n",
    "def remove_blank_traces(st):\n",
    "    for tr in st:\n",
    "        if all(tr.data==0):\n",
    "            st.remove(tr)             \n",
    "       \n",
    "    \n",
    "def set_paths(originalDMXfile, CONVERT_DIR, WINSUDSPATH):\n",
    "    paths = {}\n",
    "    if not os.path.isdir(CONVERT_DIR):\n",
    "        os.makedirs(CONVERT_DIR)\n",
    "    \n",
    "    # different versions of waveform file\n",
    "    #DMXbasename = os.path.basename(originalDMXfile)\n",
    "    #paths['IRIGfile'] = os.path.join(CONVERT_DIR, DMXbasename) # produced by irig.exe\n",
    "\n",
    "    # paths to WIN_SUDS programs\n",
    "    paths['demux.exe'] = os.path.join(WINSUDSPATH, 'demux.exe')\n",
    "    paths['irig.exe'] = os.path.join(WINSUDSPATH, 'irig.exe')\n",
    "    paths['sud2sac.exe'] = os.path.join(WINSUDSPATH, 'sud2sac.exe')\n",
    "    paths['sud2msed.exe'] = os.path.join(WINSUDSPATH, 'sud2msed.exe')\n",
    "    paths['sud2gse.exe'] = os.path.join(WINSUDSPATH, 'sud2gse.exe') \n",
    "    \n",
    "    # paths to PHA and PUN files, if they exist\n",
    "    #paths['PHAfile'] = DMXbasename.replace('.DMX','.PHA') # this might exist if HYPO71 was run to locate the event\n",
    "    #paths['PUNfile'] = DMXbasename.replace('.DMX','.PUN') # this might exist if HYPO71 was run and generated a hypocenter\n",
    "    \n",
    "    return paths  \n",
    "\n",
    "def _get_Stream_stats(st):\n",
    "    if len(st)>0:\n",
    "        s = st[0].stats\n",
    "        return s.starttime, s.sampling_rate\n",
    "    else:\n",
    "        return 0, 0\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25938252",
   "metadata": {},
   "source": [
    "# 1. Prove that it works for Montserrat data\n",
    "ObsPy now includes a reader for DMX SUDS files. We need to test this. Before applying to Pinatubo data, let's first check that it correctly reads Montserrat SUDS data that were previously converted to GSE, and then to MiniSEED. For this test, we copied 3 DMX files and the corresponding 3 GSE files from the fileserver, newton.rc.usf.edu, and stored these at Dropbox\\DATA\\Montserrat\\example_SUDS. Here are the Anaconda shell commands we used to secure-copy the data:\n",
    "\n",
    "> scp thompsong@131.247.215.87:/raid/data/Montserrat/VDAP/SUDS/1995/12/*109.DMX .\\example_SUDS\\\n",
    "> scp thompsong@131.247.215.87:PROJECTS/MASTERING/GSE/gse_not_time_corrected/1995/12/*109.gse .\\example_SUDS\\\n",
    "\n",
    "## 1.1 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd322d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINSUDSPATH = os.path.join(\"C:\", \"Users\", \"thompsong\", \"winsuds290\", \"bin\")\n",
    "TOPDIR = 'D:\\Dropbox\\DATA\\Montserrat\\example_SUDS'\n",
    "CONVERT_DIR = os.path.join(TOPDIR,'convert')\n",
    "if not os.path.isdir(CONVERT_DIR):\n",
    "    os.makedirs(CONVERT_DIR)\n",
    "    \n",
    "# Make lists of the files   \n",
    "os.system('copy D:\\Dropbox\\DATA\\Montserrat\\example_SUDS\\original\\*.DMX  D:\\Dropbox\\DATA\\Montserrat\\example_SUDS')\n",
    "allDMXfiles = glob.glob(os.path.join(TOPDIR,'*.DMX'))\n",
    "#allGSEfiles = glob.glob(os.path.join(TOPDIR,'*.GSE'))\n",
    "\n",
    "for filenum in range(len(allDMXfiles)):    \n",
    "    originalDMXfile = allDMXfiles[filenum]\n",
    "    paths = set_paths(originalDMXfile, CONVERT_DIR, WINSUDSPATH)\n",
    "    returnDF = process_one_DMXfile(originalDMXfile, run_irig=True, run_sud2gse=True, run_sud2sac=False)\n",
    "    display(HTML(returnDf.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d058efad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tryit = op.read(\"D:\\DROPBOX\\DATA\\MONTSERRAT\\EXAMPLE_SUDS\\CONVERT\\95120109.DMX\")\n",
    "print(tryit)\n",
    "tryit = op.read(\"D:\\DROPBOX\\DATA\\MONTSERRAT\\EXAMPLE_SUDS\\95120109.sac-001\")\n",
    "print(tryit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb695fe",
   "metadata": {},
   "source": [
    "## 1.2 Results\n",
    "\n",
    "### 1.2.1 Results with pre-converted GSE files\n",
    "\n",
    "In the first test, I used event files that I had converted to GSE many years ago.\n",
    "\n",
    "With Montserrat data, for each of these 3 events, and for every trace in each file, trace data vectors were the same whether read from GSE file or from DMX file and modified by -2048.0.\n",
    "\n",
    "However, the actual start times were different. It is possible that either the DMX or GSE files originate from a WVM or DMX file that did not have IRIG.exe applied. Indeed, the GSE files were from a folder called \"GSE_not_time_corrected\". Or the latter might refer to not having a correction applied between local time and UTC.\n",
    "\n",
    "A separate investigation of WVM/DMX files with IRIG.exe applied vs not applied needs to be carried out. \n",
    "\n",
    "### 1.2.2 Results with newly-converted GSE files\n",
    "\n",
    "In the second test, we started back with DMX files, and ran irig.exe, and then converted to GSE, SAC, and MiniSEED\n",
    "\n",
    "However, in each case I am getting a 'ERROR: File out of sync: May not be a SUDS file\" error message.\n",
    "\n",
    "Our code works for Montserrat data. We could now go back and re-process all the original SUDS data with this much easier method. We'd still need to use IRIG.exe and DEMUX.exe, but not SUDS2GSE.exe or SUDS2MSED.exe.\n",
    "\n",
    "Nevertheless, we can now proceed to process the Pinatubo data. The only question is whether to apply IRIG.exe. Also, it might be wise to compare two different versions, one from reading DMX file, another from converting it to GSE, SAC, or Miniseed. Also look out for changes in sampling frequency, as well as start time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374df8d",
   "metadata": {},
   "source": [
    "# 2. Checking for Pinatubo data\n",
    "\n",
    "We will now test if this works for Pinatubo data too.\n",
    "\n",
    "## 2.1 Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f392f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_DMXfile(originalDMXfile, WINSUDSPATH, run_irig=True, run_sud2gse=True, run_sud2sac=True, run_sud2msed=False):\n",
    "    \n",
    "    returnHdr = []\n",
    "    returnRow = []\n",
    "    \n",
    "    print('********************************************************************')\n",
    "    print('*** Processing %s *** ' % originalDMXfile)\n",
    "    print('********************************************************************')\n",
    "    \n",
    "    DMXfile = originalDMXfile\n",
    "    DMXbasename = os.path.basename(originalDMXfile)\n",
    "    \n",
    "    # Check that the DMX file headers are readable. If not, return blank Stream and limited resultDF\n",
    "    badDMX = False\n",
    "    try:\n",
    "        st = op.read(DMXfile, headonly=True)\n",
    "        if len(st)==0:\n",
    "            badDMX = True\n",
    "    except:\n",
    "        badDMX = True\n",
    "    if badDMX:\n",
    "        print(\"FAILED to read headers, or zero Trace in Stream. Skipping.\")\n",
    "        returnHdr.extend(['file','DMX_starttime','DMX_fsamp'])\n",
    "        returnRow.extend([DMXbasename, 0, 0])\n",
    "        return op.Stream(), pd.DataFrame([returnHdr,returnRow])#,columns=returnHdr)\n",
    "    \n",
    "    # Get starttime & sampling_rate of original DMX file\n",
    "    print('\\n********* Reading original DMX file *********')\n",
    "    st_dmx = read_DMX_file(originalDMXfile, fix=True)\n",
    "    print(st_dmx)\n",
    "    starttime_dmx, sampling_rate_dmx = _get_Stream_stats(st_dmx)\n",
    "    returnHdr.extend(['file','DMX_starttime','DMX_fsamp'])\n",
    "    returnRow.extend([DMXbasename, starttime_dmx, sampling_rate_dmx])\n",
    "\n",
    "    st_compare = st_dmx\n",
    "    \n",
    "    if run_irig:\n",
    "        \n",
    "        IRIGfile = os.path.join(CONVERT_DIR, DMXbasename) # produced by irig.exe\n",
    "        \n",
    "        # Apply IRIG.exe to ensure timestamping is correct\n",
    "        print('\\n********* Running IRIG.exe *********')\n",
    "        returnCode_irig, irig_delta_correction_secs = run_IRIG(os.path.join(WINSUDSPATH, 'irig.exe'), originalDMXfile, IRIGfile)\n",
    "        \n",
    "        # Handle return codes / malfunctions of irig.exe\n",
    "        if returnCode_irig:\n",
    "            if irig_delta_correction_secs: # None if bad\n",
    "                print('irig.exe Failed. Trying to use salvaged IRIG Delta T.')\n",
    "                if np.abs(irig_delta_correction_secs)<3600.0: \n",
    "                    st_irig = st_dmx.copy()\n",
    "                    for tr in st_irig:\n",
    "                        tr.stats.starttime += irig_delta_correction_secs\n",
    "                    print(st_irig)\n",
    "                else:\n",
    "                    st_irig = op.Stream()\n",
    "                    print('IRIG Delta T more than 1 hour. Untrustworthy. Skipping this file.')\n",
    "            else:\n",
    "                st_irig = op.Stream()\n",
    "                print('irig.exe Failed. Possibly a sequence error, or no IRIG station. Skipping this file.')\n",
    "                \n",
    "        else:  # this means irig.exe probably ran okay\n",
    "            # Read IRIG-corrected DMX file direct\n",
    "            newDMXfile = IRIGfile # this means sud2gse and sud2sac will read IRIG file, not DMX file\n",
    "            print('\\n\\n********* Reading IRIG-corrected DMX file directly *********')\n",
    "            st_irig = read_DMX_file(IRIGfile, fix=True)\n",
    "            print(st_irig)\n",
    "            st_compare = st_irig\n",
    "        starttime_irig, sampling_rate_irig = _get_Stream_stats(st_irig)\n",
    "        returnHdr.extend(['irig_rtnCode','deltaT','IRIG_starttime','IRIG_fsamp'])        \n",
    "        returnRow.extend([returnCode_irig, irig_delta_correction_secs, \n",
    "                          starttime_irig, sampling_rate_irig]) \n",
    "    \n",
    "    # SUDS DMX to GSE using sud2gse. Then ObsPy to read GSE into Stream.\n",
    "    if run_sud2gse:\n",
    "        print('\\n\\n********* Reading via Conversion to GSE *********')        \n",
    "        st_sud2gse = SUDSDMX_to_GSE_to_STREAM(os.path.join(WINSUDSPATH, 'sud2gse.exe'), DMXfile) \n",
    "        print(st_sud2gse)\n",
    "        if len(st_sud2gse)>0 and st_compare:\n",
    "            #print('read via conversion to GSE complete\\n') \n",
    "            print('\\n*** Comparing DMX reader vs sud2gse')\n",
    "            compare_Streams(st_compare, st_sud2gse)\n",
    "        starttime_gse, sampling_rate_gse = _get_Stream_stats(st_sud2gse)\n",
    "        returnHdr.extend(['GSE_starttime','GSE_fsamp']) \n",
    "        returnRow.extend([starttime_gse, sampling_rate_gse])             \n",
    "        \n",
    "    # SUDS DMX to SAC using sud2sac. Then ObsPy to read GSE into Stream.\n",
    "    if run_sud2sac:\n",
    "        print('\\n\\n********* Reading via Conversion to SAC *********')         \n",
    "        st_sud2sac = SUDSDMX_to_SAC_to_STREAM(os.path.join(WINSUDSPATH, 'sud2sac.exe'), DMXfile) \n",
    "        print(st_sud2sac)\n",
    "        if len(st_sud2sac)>0 and st_compare:\n",
    "            #print('read via conversion to SAC complete\\n') \n",
    "            print('\\n*** Comparing DMX reader vs sud2sac')\n",
    "            compare_Streams(st_compare, st_sud2sac)\n",
    "        starttime_sac, sampling_rate_sac = _get_Stream_stats(st_sud2sac)\n",
    "        returnHdr.extend(['SAC_starttime','SAC_fsamp'])            \n",
    "        returnRow.extend([starttime_sac, sampling_rate_sac])  \n",
    "        \n",
    "    # SUDS DMX to MSEED using sud2msed. Then ObsPy to read MSEED into Stream.     \n",
    "    if run_sud2msed:\n",
    "        # sud2msed.exe does not work - it hangs or something - and it also loses all tr.id info\n",
    "        st_sud2msed = SUDSDMX_to_MSED_to_STREAM(os.path.join(WINSUDSPATH, 'sud2msed.exe'), DMXfile) \n",
    "        print(st_sud2msed)\n",
    "        if len(st_sud2msed)>0 and st_compare:\n",
    "            #print('read via conversion to MSEED complete\\n') \n",
    "            print('\\n*** Comparing DMX reader vs sud2msed')\n",
    "            compare_Streams(st_compare, st_sud2msed) \n",
    "        starttime_msd, sampling_rate_msd = _get_Stream_stats(st_sud2msed)\n",
    "        returnHdr.extend(['MSD_starttime','MSD_fsamp'])          \n",
    "        returnRow.extend([starttime_msd, sampling_rate_msd])  \n",
    "        \n",
    "    # returns    \n",
    "    #print(returnHdr, returnRow)\n",
    "    return st_compare, pd.DataFrame([returnHdr,returnRow])#,columns=returnHdr)\n",
    "\n",
    "def _Stream_to_SEISANWAV_filename_translation(st, SEISAN_TOP, seisanDBname):\n",
    "    # Establishing the Seisan WAV filename corresponding to this Stream\n",
    "    WAVbasename = \"%sM.%s_%03d\" % (st[0].stats.starttime.strftime('%Y-%m-%d-%H%M-%S'), seisanDBname, len(st))\n",
    "    WAVfilename = os.path.join(SEISAN_TOP, 'WAV', seisanDBname, \n",
    "        st[0].stats.starttime.strftime('%Y'), \n",
    "        st[0].stats.starttime.strftime('%m'),\n",
    "        WAVbasename)    \n",
    "    return WAVfilename\n",
    "\n",
    "def register_Stream_into_SeisanDB(st, SEISAN_TOP, seisanDBname):\n",
    "    ### REGISTERING THIS EVENT FILE INTO SEISAN\n",
    "    # Check if it already exists in Seisan DB WAV\n",
    "    WAVfilename = _Stream_to_SEISANWAV_filename_translation(st, SEISAN_TOP, seisanDBname)\n",
    "    \n",
    "    if os.path.exists(WAVfilename):\n",
    "        print('%s exists' % WAVfilename)\n",
    "        return 1\n",
    "    else:\n",
    "        # Add this Miniseed event waveform file to the Seisan database.\n",
    "        # The Miniseed file will be moved to [SEISANTOP]/WAV/[SEISANDB]/YYYY/MM\n",
    "        # A corresponding Seisan S-file (event metadata file) will be created at [SEISANTOP]/REA/[SEISANDB]/YYYY/MM\n",
    "        # The Seisan programs MAKEREA and AUTOREG are used here. Since they normally require user input, \n",
    "        # we create files to simulate this. \n",
    "        WAVbasename = os.path.basename(WAVfilename)\n",
    "        #\n",
    "        # MAKEREA\n",
    "        # old stuff. was getting YYYY & MM from DMX file\n",
    "        #DMXbasename = os.path.basename(originalDMXfile)\n",
    "        #yy = DMXbasename[0:2]\n",
    "        #mm = DMXbasename[2:4]\n",
    "        #century = '19'\n",
    "        #if yy < '80':\n",
    "        #    century = '20'\n",
    "        #yyyy = century + yy\n",
    "        # New stuff. get YYYY & MM from starttime \n",
    "        yyyy = st[0].stats.starttime.strftime('%Y')\n",
    "        mm = st[0].stats.starttime.strftime('%m')\n",
    "        fptr = open('makerea_wrapper.txt','w')\n",
    "        fptr.write(seisanDBname + '\\n')\n",
    "        fptr.write(yyyy + mm + '\\n')\n",
    "        fptr.write('\\n')\n",
    "        fptr.write('BOTH\\n')\n",
    "        fptr.close()\n",
    "        cmd = 'makerea < makerea_wrapper.txt'\n",
    "        rtncode, result = _run_command(cmd, show_terminal_output=True)\n",
    "        \n",
    "        #os.system('makerea < makerea_wrapper.txt')\n",
    "        #\n",
    "        # Copy the miniseed file to WOR BEFORE running dirf and autoreg\n",
    "        WORpath = os.path.join(SEISAN_TOP,'WOR')\n",
    "        WORfile = os.path.join(WORpath, WAVbasename)\n",
    "        if not os.path.isfile(WORfile):\n",
    "            try: \n",
    "                st.write(WORfile,'mseed')\n",
    "            except:\n",
    "                print('FAILED to write')\n",
    "                return 2 \n",
    "        #\n",
    "        # DIRF    \n",
    "        cwd=os.getcwd()\n",
    "        print('cwd = ' + cwd)\n",
    "        os.chdir(WORpath)\n",
    "        #os.system('dirf ' + os.path.basename(WORfile))\n",
    "        cmd = 'dirf ' + WAVbasename\n",
    "        try:\n",
    "            rtncode, result = _run_command(cmd, show_terminal_output=True)\n",
    "            if rtncode:\n",
    "                return 3\n",
    "        except:\n",
    "            return 4\n",
    "        #\n",
    "        # AUTOREG\n",
    "        fptr = open('autoreg_wrapper.txt','w')\n",
    "        fptr.write('L\\n')\n",
    "        fptr.write('m\\n')\n",
    "        fptr.write(seisanDBname + '\\n')\n",
    "        fptr.write('gt\\n')\n",
    "        fptr.close()\n",
    "        #os.system('autoreg < autoreg_wrapper.txt')\n",
    "        cmd = 'autoreg < autoreg_wrapper.txt'\n",
    "        try:\n",
    "            rtncode, result = _run_command(cmd, show_terminal_output=True)\n",
    "            if rtncode:\n",
    "                return 5\n",
    "        except:\n",
    "            return 6\n",
    "        os.chdir(cwd)\n",
    "        \n",
    "        return 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Main paths for SUDS DMX\n",
    "TOPDIR = 'D:\\Dropbox\\DATA\\Pinatubo'\n",
    "WAVEFORM_DIR = os.path.join(TOPDIR,'WAVEFORMS')\n",
    "CONVERT_DIR = os.path.join(TOPDIR,'convert')\n",
    "\n",
    "# paths for files to register into Seisan\n",
    "os.environ['SEISAN_TOP']='D:\\Dropbox\\DATA\\SEISAN_DB'\n",
    "seisanDBname = 'PINAT'\n",
    "\n",
    "# Clean environment\n",
    "if os.path.isdir(CONVERT_DIR): # remove and recreate convert directory\n",
    "    shutil.rmtree(CONVERT_DIR)\n",
    "os.makedirs(CONVERT_DIR)\n",
    "os.chdir(CONVERT_DIR)    \n",
    "WORpath = os.path.join(os.getenv('SEISAN_TOP'),'WOR')\n",
    "if os.path.isdir(WORpath): # remove files in WOR\n",
    "    for file in glob.glob(os.path.join(WORpath, '2*%s*' % seisanDBname)):\n",
    "        os.remove(file)\n",
    "WAVpath = os.path.join(os.getenv('SEISAN_TOP'),'WAV',seisanDBname)\n",
    "if os.path.isdir(WAVpath): # remove files in WAV\n",
    "    shutil.rmtree(WAVpath)\n",
    "REApath = os.path.join(os.getenv('SEISAN_TOP'),'REA',seisanDBname)\n",
    "if os.path.isdir(REApath): # remove files in REA\n",
    "    shutil.rmtree(REApath)    \n",
    "\n",
    "\n",
    "# Other constants\n",
    "FDSNnet = 'XB' # assigned by Gale Cox. 1R is code for KSC.\n",
    "WINSUDSPATH = os.path.join(\"C:\", \"Users\", \"thompsong\", \"winsuds290\", \"bin\")\n",
    "\n",
    "#originalDMXFile = os.path.join(WAVEFORM_DIR, '199105', '9105011P.DMX')\n",
    "originalDMXfile = os.path.join(WAVEFORM_DIR, '199112', '9112010B.DMX')\n",
    "paths = set_paths(originalDMXfile, CONVERT_DIR, WINSUDSPATH)\n",
    "\n",
    "st, returnDf = process_one_DMXfile(originalDMXfile, run_irig=True, run_sud2gse=True, run_sud2sac=False)\n",
    "print(st)\n",
    "display(HTML(returnDf.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea69b42",
   "metadata": {},
   "source": [
    "Next modify the following to use process_one_DMXfile(originalDMXfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _Stream_to_SEISANWAV_filename_translation(st, SEISAN_TOP, seisanDBname):\n",
    "    # Establishing the Seisan WAV filename corresponding to this Stream\n",
    "    WAVbasename = \"%sM.%s_%03d\" % (st[0].stats.starttime.strftime('%Y-%m-%d-%H%M-%S'), seisanDBname, len(st))\n",
    "    WAVfilename = os.path.join(SEISAN_TOP, 'WAV', seisanDBname, \n",
    "        st[0].stats.starttime.strftime('%Y'), \n",
    "        st[0].stats.starttime.strftime('%m'),\n",
    "        WAVbasename)    \n",
    "    return WAVfilename\n",
    "\n",
    "def register_Stream_into_SeisanDB(st, SEISAN_TOP, seisanDBname):\n",
    "    ### REGISTERING THIS EVENT FILE INTO SEISAN\n",
    "    # Check if it already exists in Seisan DB WAV\n",
    "    WAVfilename = _Stream_to_SEISANWAV_filename_translation(st, SEISAN_TOP, seisanDBname)\n",
    "    \n",
    "    if os.path.exists(WAVfilename):\n",
    "        print('%s exists' % WAVfilename)\n",
    "        return 1\n",
    "    else:\n",
    "        # Add this Miniseed event waveform file to the Seisan database.\n",
    "        # The Miniseed file will be moved to [SEISANTOP]/WAV/[SEISANDB]/YYYY/MM\n",
    "        # A corresponding Seisan S-file (event metadata file) will be created at [SEISANTOP]/REA/[SEISANDB]/YYYY/MM\n",
    "        # The Seisan programs MAKEREA and AUTOREG are used here. Since they normally require user input, \n",
    "        # we create files to simulate this. \n",
    "        WAVbasename = os.path.basename(WAVfilename)\n",
    "        #\n",
    "        # MAKEREA\n",
    "        # old stuff. was getting YYYY & MM from DMX file\n",
    "        #DMXbasename = os.path.basename(originalDMXfile)\n",
    "        #yy = DMXbasename[0:2]\n",
    "        #mm = DMXbasename[2:4]\n",
    "        #century = '19'\n",
    "        #if yy < '80':\n",
    "        #    century = '20'\n",
    "        #yyyy = century + yy\n",
    "        # New stuff. get YYYY & MM from starttime \n",
    "        yyyy = st[0].stats.starttime.strftime('%Y')\n",
    "        mm = st[0].stats.starttime.strftime('%m')\n",
    "        fptr = open('makerea_wrapper.txt','w')\n",
    "        fptr.write(seisanDBname + '\\n')\n",
    "        fptr.write(yyyy + mm + '\\n')\n",
    "        fptr.write('\\n')\n",
    "        fptr.write('BOTH\\n')\n",
    "        fptr.close()\n",
    "        cmd = 'makerea < makerea_wrapper.txt'\n",
    "        rtncode, result = _run_command(cmd, show_terminal_output=True)\n",
    "        \n",
    "        #os.system('makerea < makerea_wrapper.txt')\n",
    "        #\n",
    "        # Copy the miniseed file to WOR BEFORE running dirf and autoreg\n",
    "        WORpath = os.path.join(SEISAN_TOP,'WOR')\n",
    "        WORfile = os.path.join(WORpath, WAVbasename)\n",
    "        if not os.path.isfile(WORfile):\n",
    "            try: \n",
    "                st.write(WORfile,'mseed')\n",
    "            except:\n",
    "                print('FAILED to write')\n",
    "                return 2 \n",
    "        #\n",
    "        # DIRF    \n",
    "        cwd=os.getcwd()\n",
    "        print('cwd = ' + cwd)\n",
    "        os.chdir(WORpath)\n",
    "        #os.system('dirf ' + os.path.basename(WORfile))\n",
    "        cmd = 'dirf ' + WAVbasename\n",
    "        try:\n",
    "            rtncode, result = _run_command(cmd, show_terminal_output=True)\n",
    "            if rtncode:\n",
    "                return 3\n",
    "        except:\n",
    "            return 4\n",
    "        #\n",
    "        # AUTOREG\n",
    "        fptr = open('autoreg_wrapper.txt','w')\n",
    "        fptr.write('L\\n')\n",
    "        fptr.write('m\\n')\n",
    "        fptr.write(seisanDBname + '\\n')\n",
    "        fptr.write('gt\\n')\n",
    "        fptr.close()\n",
    "        #os.system('autoreg < autoreg_wrapper.txt')\n",
    "        cmd = 'autoreg < autoreg_wrapper.txt'\n",
    "        try:\n",
    "            rtncode, result = _run_command(cmd, show_terminal_output=True)\n",
    "            if rtncode:\n",
    "                return 5\n",
    "        except:\n",
    "            return 6\n",
    "        os.chdir(cwd)\n",
    "        \n",
    "        return 0\n",
    "\n",
    "\n",
    "# Main paths\n",
    "TOPDIR = 'D:\\Dropbox\\DATA\\Pinatubo'\n",
    "WAVEFORM_DIR = os.path.join(TOPDIR,'WAVEFORMS')\n",
    "\n",
    "# paths for different conversions\n",
    "CONVERT_DIR = os.path.join(TOPDIR,'convert')\n",
    "if not os.path.isdir(CONVERT_DIR):\n",
    "    os.makedirs(CONVERT_DIR)\n",
    "os.chdir(CONVERT_DIR)\n",
    "\n",
    "# paths for files to register into Seisan\n",
    "os.environ['SEISAN_TOP']='D:\\Dropbox\\DATA\\SEISAN_DB'\n",
    "SEISAN_TOP = os.getenv('SEISAN_TOP')\n",
    "seisanDBname = 'PINAT'\n",
    "WORpath = os.path.join(os.getenv('SEISAN_TOP'),'WOR')\n",
    "\n",
    "# Other constants\n",
    "FDSNnet = 'XB' # assigned by Gale Cox. 1R is code for KSC.\n",
    "WINSUDSPATH = os.path.join(\"C:\", \"Users\", \"thompsong\", \"winsuds290\", \"bin\")\n",
    "#paths = set_paths(originalDMXfile, CONVERT_DIR, WINSUDSPATH)\n",
    "\n",
    "# Loop over all files\n",
    "returnDFs = pd.DataFrame()\n",
    "alldirs = glob.glob(os.path.join(WAVEFORM_DIR, '*'))\n",
    "for thisdir in alldirs:\n",
    "    allDMXfiles = glob.glob(os.path.join(thisdir, '*.DMX'))\n",
    "    for originalDMXfile in allDMXfiles:\n",
    "        \n",
    "        # DMX processing\n",
    "        st, returnDF = process_one_DMXfile(originalDMXfile, WINSUDSPATH, run_irig=True, run_sud2gse=True, run_sud2sac=False)\n",
    "        remove_blank_traces(st)\n",
    "        if len(st)==0:\n",
    "            # Bad Stream/event. Nothing to do.\n",
    "            continue      \n",
    "        fix_NSLC_Pinatubo(st, FDSNnet)    \n",
    "        \n",
    "        # Establishing the Seisan WAV filename corresponding to this SUDS DMX event filename\n",
    "        WAVfilename = _Stream_to_SEISANWAV_filename_translation(st, SEISAN_TOP, seisanDBname)\n",
    "        \n",
    "        # Registering into Seisan\n",
    "        rtncode = register_Stream_into_SeisanDB(st, SEISAN_TOP, seisanDBname)\n",
    "        \n",
    "        # Save WAV filename & return code to dataframe, concatenate, save\n",
    "        returnDF['SEISAN_WAV_filename']=os.path.basename(WAVfilename)\n",
    "        returnDF['registered']=rtncode\n",
    "        display(HTML(returnDF.to_html()))\n",
    "        returnDFs = pd.concat([returnDFs, returnDF])\n",
    "        returnDFs.to_csv('pinatubo_processing.csv') # Save each time in case of crash before processing all files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d919748",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
