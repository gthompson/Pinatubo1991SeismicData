{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from obspy.core.event import Catalog, Event, Origin, Pick\n",
    "from obspy.core import UTCDateTime, read_events\n",
    "\n",
    "def print_event(ev, times_only=False):\n",
    "    for origin in ev.origins:\n",
    "        if times_only:\n",
    "            print(origin.time)\n",
    "        else:\n",
    "            print(origin)    \n",
    "    for pick in ev.picks:\n",
    "        if times_only:\n",
    "            print(pick.time, pick.waveform_id)\n",
    "        else:\n",
    "            print(pick)\n",
    "\n",
    "SOURCE_DIR = '/data/Pinatubo/PHASE'\n",
    "REPO_DIR = '/home/thompsong/Developer/Pinatubo1991SeismicData'\n",
    "REA_DIR = '/data/SEISAN_DB/REA/PINAT'\n",
    "WAV_DIR = '/data/SEISAN_DB/WAV/PINAT'\n",
    "srcqmlfile = os.path.join(SOURCE_DIR, 'all_events.xml') # original QuakeML file generated by 30_eventcsv2qml\n",
    "fixedqmlfile = os.path.join(REPO_DIR, 'metadata', 'fixed_events.xml') # catalog fixed by cutting picks that do not match, and creating new events from them\n",
    "wavqmlfile = os.path.join(REPO_DIR, 'metadata', 'wav_events.xml') # catalog where corresponding wav file is in the comments of the event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the QuakeML file we created with 30_eventcsv2qml.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmlfile = os.path.join(SOURCE_DIR, 'all_events.xml')\n",
    "catalog = read_events(srcqmlfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default origin time is identical to the earliest pick time in the event.\n",
    "Find any picks which do not seem to make sense for this event, because they are more than 60-s later (maybe it should be 10-s for P, 17-s for S?)\n",
    "Create new events from the bad picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_bad_picks(catalog, time_threshold=60):\n",
    "    \"\"\"\n",
    "    Identifies picks that are too far (> time_threshold) from their event's origin time,\n",
    "    removes them from the original events, and creates new Event objects.\n",
    "\n",
    "    Parameters:\n",
    "        catalog (obspy.core.event.Catalog): The ObsPy Catalog containing multiple events.\n",
    "        time_threshold (int, optional): The maximum allowed time difference (default: 60s).\n",
    "\n",
    "    Returns:\n",
    "        obspy.core.event.Catalog: A new catalog with fixed events and separate bad pick events.\n",
    "    \"\"\"\n",
    "    new_catalog = Catalog()  # Store fixed events\n",
    "    bad_picks = []  # Collect picks that need to be in separate events\n",
    "\n",
    "    for event in catalog:\n",
    "        if not event.origins:\n",
    "            new_catalog.append(event)  # Skip if no origin time\n",
    "            continue\n",
    "        \n",
    "        origin_time = event.origins[0].time\n",
    "        valid_picks = []\n",
    "        \n",
    "        # Separate bad picks\n",
    "        for pick in event.picks:\n",
    "            if abs((pick.time - origin_time)) > time_threshold:\n",
    "                bad_picks.append(pick)  # Collect for new event\n",
    "            else:\n",
    "                valid_picks.append(pick)  # Keep in original event\n",
    "\n",
    "        # Update original event with only valid picks\n",
    "        if valid_picks:\n",
    "            event.picks = valid_picks\n",
    "            new_catalog.append(event)  # Save the cleaned event\n",
    "\n",
    "    # ðŸ”¹ Step 2: Create new events from bad picks\n",
    "    while bad_picks:\n",
    "        first_pick = bad_picks.pop(0)  # Take the first pick to start a new event\n",
    "        sorted_times = sorted([p.time for p in bad_picks])\n",
    "        min_time = sorted_times[0]        \n",
    "        new_event = Event()\n",
    "        #new_event.picks.append(first_pick)\n",
    "\n",
    "        # Find other picks close in time\n",
    "        related_picks = [p for p in bad_picks if abs(p.time - min_time) < time_threshold]\n",
    "        for p in related_picks:\n",
    "            new_event.picks.append(p)\n",
    "            bad_picks.remove(p)  # Remove from processing\n",
    "\n",
    "        # Set an estimated origin time based on earliest pick\n",
    "        estimated_origin = Origin(time=min(p.time for p in new_event.picks))\n",
    "        new_event.origins.append(estimated_origin)\n",
    "        new_catalog.append(new_event)\n",
    "\n",
    "    return new_catalog\n",
    "\n",
    "# Example usage:\n",
    "#catalog = Catalog.read(srcqmlfile, format=\"QUAKEML\")  # Load the original catalog\n",
    "fixed_catalog = separate_bad_picks(catalog, time_threshold=60)\n",
    "\n",
    "# Save the fixed catalog back to QuakeML\n",
    "fixed_catalog.write(fixedqmlfile, format=\"QUAKEML\")\n",
    "print(f\"Fixed catalog saved as {fixedqmlfile}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write fixed Catalog to Seisan REA database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from obspy.io.nordic.core import _write_nordic\n",
    "def save_catalog_to_seisan(catalog, output_dir):\n",
    "    \"\"\"\n",
    "    Saves an ObsPy Catalog as Seisan REA database S-files in Nordic format using `_write_nordic`.\n",
    "\n",
    "    Parameters:\n",
    "        catalog (obspy.core.event.Catalog): The ObsPy Catalog containing multiple events.\n",
    "        output_dir (str): Directory where S-files will be saved.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure the REA directory exists\n",
    "\n",
    "    for event in catalog:\n",
    "        # Get the origin time (used for the filename)\n",
    "        if not event.origins:\n",
    "            print(f\"Skipping event {event} (no origin time)\")\n",
    "            continue\n",
    "\n",
    "        \n",
    "        origin_time = event.origins[0].time  # Use the first origin time\n",
    "        ymdir = os.path.join(output_dir, f'{origin_time.year:4d}', f'{origin_time.month:02d}')\n",
    "        if not os.path.isdir(ymdir):\n",
    "            os.makedirs(ymdir)\n",
    "        \n",
    "        # Note: do not actually need to generate filename, as passing None forces ObsPy to generate it\n",
    "        filename = origin_time.strftime(\"%d-%H%M-%S\") + \"L.S\" + origin_time.strftime(\"%Y%m\")  # Seisan S-file naming convention\n",
    "        file_path = os.path.join(ymdir, filename)   \n",
    "        #print(file_path)   \n",
    "\n",
    "        # Write the event to a Nordic file using `_write_nordic`\n",
    "        try:\n",
    "            _write_nordic(event, filename, userid='gt', evtype='L', outdir=ymdir, wavefiles=None, \n",
    "                      explosion=False, nordic_format='OLD', overwrite=True, high_accuracy=False)\n",
    "        except Exception as e:\n",
    "            print('\\nBAD EVENT: ',file_path)\n",
    "            print(e)\n",
    "            print_event(event)\n",
    "            #input('ENTER')\n",
    "            continue\n",
    "        #else:\n",
    "        #    print(f\"âœ… Saved Seisan S-file: {file_path}\")\n",
    "\n",
    "# Example usage:\n",
    "#fixed_catalog = obspy.read_events(fixedqml, format=\"QUAKEML\")  # Load the QuakeML catalog\n",
    "\n",
    "# Convert and save the Catalog to Seisan\n",
    "save_catalog_to_seisan(fixed_catalog, REA_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to associate a MiniSEED file to each Event in the Catalog. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from obspy import read, UTCDateTime\n",
    "from obspy.core.event import Catalog, Comment\n",
    "\n",
    "def associate_miniseed_with_events(catalog, wav_directory):\n",
    "    \"\"\"\n",
    "    Associates MiniSEED files from a Seisan WAV database with Pick objects in an ObsPy Catalog.\n",
    "    If a Pick's time falls within a MiniSEED file's time range, a Comment is added to the Event.\n",
    "\n",
    "    Parameters:\n",
    "        catalog (obspy.core.event.Catalog): The ObsPy Catalog containing Events with Picks.\n",
    "        wav_directory (str): Path to the Seisan WAV database (e.g., \"WAV/\").\n",
    "\n",
    "    Returns:\n",
    "        obspy.core.event.Catalog: The updated Catalog with associated MiniSEED file paths in Comments.\n",
    "    \"\"\"\n",
    "\n",
    "    # ðŸ”¹ Step 1: Load MiniSEED files and extract time windows\n",
    "    miniseed_files = sorted(glob.glob(os.path.join(wav_directory, \"PINAT/1991/??/1991*\"), recursive=True))  # Adjust pattern if needed\n",
    "    miniseed_time_ranges = []\n",
    "\n",
    "    for file in miniseed_files:\n",
    "        try:\n",
    "            stream = read(file)\n",
    "            start_time = min(tr.stats.starttime for tr in stream)\n",
    "            end_time = max(tr.stats.endtime for tr in stream)\n",
    "            miniseed_time_ranges.append((file, start_time, end_time))\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error reading {file}: {e}\")\n",
    "    \n",
    "    print(f\"âœ… Loaded {len(miniseed_time_ranges)} MiniSEED files for association.\")\n",
    "\n",
    "    # ðŸ”¹ Step 2: Iterate through Events & Picks to check time association\n",
    "    for event in catalog:\n",
    "        associated_files = set()  # Track unique MiniSEED files per event\n",
    "        \n",
    "        for pick in event.picks:\n",
    "            pick_time = pick.time  # Extract pick time\n",
    "\n",
    "            # Check if Pick falls within any MiniSEED file time range\n",
    "            for file_path, start_time, end_time in miniseed_time_ranges:\n",
    "                if start_time <= pick_time <= end_time:\n",
    "                    associated_files.add(file_path)\n",
    "\n",
    "        # ðŸ”¹ Step 3: Add MiniSEED file paths as Comments in Event\n",
    "        if associated_files:\n",
    "            comment_text = \"Associated MiniSEED files:\\n\" + \"\\n\".join(sorted(associated_files))\n",
    "            event.comments.append(Comment(text=comment_text))\n",
    "            print(f\"ðŸ“Œ Added MiniSEED association for Event at {event.origins[0].time}\")\n",
    "\n",
    "    return catalog\n",
    "\n",
    "# Example usage:\n",
    "#fixed_catalog = Catalog.read(fixedqmlfile, format=\"QUAKEML\")  # Load corrected catalog\n",
    "\n",
    "# Associate MiniSEED files with events\n",
    "wav_catalog = associate_miniseed_with_events(fixed_catalog, WAV_DIR)\n",
    "\n",
    "# Save the updated catalog with comments\n",
    "wav_catalog.write(wavqmlfile, format=\"QUAKEML\")\n",
    "print(f\"\\nâœ… Updated catalog saved as {wavqmlfile}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do:\n",
    "- We are doing the association the wrong way around. First, we should create a REA file for every WAV file. But as we do it, we should look for pick times that fall within the corresponding Stream start & end times, and write those out with the event.\n",
    "- We also should look at the summary files, and try to add any hypocenters and magnitudes we have to any events\n",
    "- Finally, we should include the STATION0.HYP file, and make a StationXML file with at least the coordinates of each station. Also provide a mapping table from the old Trace IDs to the new ones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "passoft3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
